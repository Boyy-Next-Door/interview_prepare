# 三范式和BCNF
## 三范式

1. 字段具有原子性，不可再分。
2. 表一定要有一个主键，非主键属性一定要完全依赖于主键，而不能只依赖主键的一部分。

    可以理解为field = f(primary_key1, primary_key2...,primary_key3)，而不能仅通过一部分primary_key就能够唯一确定一个field。

    典型的就是t_student(stu_id, name, teacher_id, teacher_name) 如果想要知道一个老师叫什么名字，你只要去表里找到与他teacher_id相同的记录，而不需要管这条记录的stu_id是多少。

    本质上就是这些部分函数依赖于主属性的字段，在这个表里冗余存储了，应该摘出去。
3. 消除非主属性对主键的传递依赖。


```go
// 注：候选码 可以理解为 用于确定表中具体某一行元素，所需要用到的所有字段的集合（通常来说一张表的候选码可以有很多组）。
// 主码可以简单理解为表的主键（强调复合主键）
// t_score(student_id, course_id, score, teacher_id, leader_id) 这表里 需要用到学生id和课程id才能确定某行数据，那么student_id和course_id就是一组候选码。
```

要知道一行记录的score值是多少，就一定要同时知道student_id和course_id，所以socre完全依赖与候选码。

显然，score就是完全依赖于候选码的。

而teacher_id其实是可以有course_id来唯一确定的，即在这张表里随便找到course_id为这个值的记录，teacher_id一定是一样的。这说明老师的id在分数表里是冗余的，teacher_id部分依赖于候选码。

再看leader_id老师的上级领导id，我们一旦知道student_id和course_id，就能知道teacher_id是多少，而我们一旦知道teacher_id是多少，就可以去表里找任意teacher_id与其相同的，这些记录的leader_id一定是一样的。说明老师的领导id也是被冗余在score表里的，它传递依赖于候选码。

三范式的目的就是让一张表只记录一种实体，尽可能消除数据冗余，以减少插入、更新和删除异常的发生。

## BCNF
任意一组候选码中的任意一个字段，都不能部分或传递依赖于其他任意一组候选码。

假定 一个教师只会教一门课程，一门课可以有很多老师教且当学生选定某门课，就对应一个固定的教师
举例：学生id 课程id 教师id
那我们可以 确定两个候选键（学生id,课程id）,(学生id，教师id)
但我们发现 一个教师只会教一门课程，那么 教师id就决定了课程id 可以认为课程id依赖于教师id 那么这个表就不符合 bcnf。

# SQL优化思路
从优化成本由低到高来考虑，大概会有以下几个优化步骤：
1. 首先看sql本身的问题，这里分成三部分来考虑
    - 选择的字段，按需取数，仅查询那些业务真正需要用到的字段，避免手写sql时select *，因为db的执行器还需要把*替换成表里的全部字段，这里开销不小。
    - 看联表，优先使用带有方向的join，这样能明确把控驱动方向，由小表驱动大表，即把left join左边的想象为外层循环(驱动)，右边的内层循环(被驱动)，20w条数据里根据索引关联1条数据循环20次，与20条数据里关联1条数据循环20w次，正常情况下前者效率高，注意关联条件中的字段类型要一致，保证能走索引进行匹配。另一方面，业务上需要对关联表的数量做出严格限制，不允许超过三张表的关联查询，可以做字段冗余、内存缓存或者sql拆分在业务层组装。
    - 看查询条件，避免写出复杂的子查询、嵌套查询、CTE等骚操作，维护成本高、性能隐患大。使用explain查看执行计划，关注type、key和extra，保证所有查询子句尽可能达到range及以上的访问类型，针对使用到的各个key，关注extra中有没有利用到覆盖索引(using index)、涉及到排序的是利用了索引顺序还是内存排序(using file sort)、看能否开启并利用索引下推来优化并不完全适配索引结构的业务查询;另一方面，所创建的索引需要将区分度高的字段放前面，尽可能地复用和拓展索引，而不是新建索引，一张表的辅助索引数量不超过5个，每个复合索引的字段值不超过5个，字符串类型（尤其指基数巨大的字符串）的字段添加索引时要指定长度，控制整个索引的长度。
2. 看表设计上的问题，业务模型中的一对一、一对多、多对多关系是否使用了恰当的表设计，一对一不需要关系表，一对多、多对多则引入中间关系表。另一方面，又需要适时打破三大范式，对那些不容易变更的、或者一致性要求没那么高的字段做冗余，减少业务中表之间的关联查询。表字段类型和长度的选择上也要充分考虑业务属性和拓展性（曾经因为一个extra字段长度不够，而多次引发系统故障）。
3. 当表结构设计和sql都优化到位了，但sql执行还是很慢，那就说明是表中的数据本身规模太大了，需要采用水平和垂直分表来缩小表的大小。
    - 当单表对应实体过于复杂，属性字段过多时，可以采用垂直分表，对字段进行冷热分离存储，那些不常使用到的字段放入detail表中，常用字段留在主表，这样可以很高程度提高主表的查询效率（可以从主键索引的B+树结构来解释）
    - 当单表数据量巨大时，会导致B+树层级过高（int主键4000W，bigint2000W），影响读写效率，于是可以进行水平分表；这时候则需要结合业务场景（范围查询？排序？精确匹配？）来选出合适的分表键和分表策略，常用的有range和hash两种，前者根据某个字段的数值范围做分表，后者根据某个字段哈希之后的值取模来分表。

4. 如果业务的瓶颈在于db的网络带宽的磁盘I/O效率，那么可能需要考虑进行db分库并引入读写分离的架构。

    通过dao层路由或者中间件的方式实现读写流量分离，让主节点负责全部的写流量，而读流量由从节点分担。
    
    在读写分离模式下，mysql默认使用异步同步策略，即主节点的dump线程将binlog变更发送给从节点的I/O线程之后，并不关心从节点是否写入relaylog并执行成功，可能存在写数操作之后短暂的数据不一致。
    
    在不改变mysql的异步复制策略的情况下，如果业务只要求最终一致性，那其实mysql异步复制也能满足，如果涉及到redis缓存，则只要给缓存设置过期时间，也能保证最终一致性；
    
    如果业务要求强一致性，那只能对所有数据加分布式读写锁，如果要修改db，那就加写锁，让写锁在从节点复制最大时延之后自动过期，就能保证业务读到的是最新的数据，不过这也会大大降低业务的并发度。

    > 以下记录一下使用docker搭建mysql主从架构的过程
    - 主节点
        - .cnf文件加入配置

        ```bash
        # 开启binlog 并设置与从节点不相同的server-id
        [mysqld]
        log-bin=mysql-bin
        server-id=1
        ```
        - 通过docker启动master节点
        ```bash
        docker run --name mysql-master -v /root/mysql/my_master.cnf:/etc/mysql/conf.d/my.cnf -v /root/mysql/master:/var/lib/mysql --network mysql-m-s -e MYSQL_ROOT_PASSWORD=xxx -dp 3306:3306  mysql_5.7_vim:1.0.0
        ```
        - 为从节点创建账号
        ```sql
        CREATE USER 'testslave'@'%' IDENTIFIED BY '123456';
        GRANT REPLICATION SLAVE ON *.* TO 'testslave'@'%' WITH GRANT OPTION;
        ```
        - 查看binlog状态
        ```sql
        # 这里可以看到当前master正在写的binlog文件以及偏移量  slave需要借助这两个参数去做增量同步
        mysql> SHOW MASTER STATUS;
        +------------------+----------+--------------+------------------+-------------------+
        | File             | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |
        +------------------+----------+--------------+------------------+-------------------+
        | mysql-bin.000004 |     2891 |              |                  |                   |
        +------------------+----------+--------------+------------------+-------------------+
        1 row in set (0.00 sec)
    
        ```
    - 从节点
         - .cnf文件加入配置
        ```bash
        # 开启binlog 并设置与主节点和其他从节点不相同的server-id
        [mysqld]
        server-id=2
        # 忽略master的系统库
        replicate-wild-ignore-table=mysql.*
        replicate-wild-ignore-table=sys.*
        ```
        - 通过docker启动slave节点
        ```bash
        docker run --name mysql-master -v /root/mysql/my_slave_1.cnf:/etc/mysql/conf.d/my.cnf -v /root/mysql/slave1:/var/lib/mysql --network mysql-m-s -e MYSQL_ROOT_PASSWORD=xxx -dp 3316:3306  mysql_5.7_vim:1.0.0
        ```
        - 配置主节点信息、开启I/O线程
        ```sql
        mysql> CHANGE MASTER TO 
            -> MASTER_HOST='mysql-master',
            -> MASTER_PORT=3306,
            -> MASTER_USER='testslave',
            -> MASTER_PASSWORD='123456',
            -> MASTER_LOG_FILE='mysql-bin.000001',   # 如果要从头开始复制 就填000001
            -> MASTER_LOG_POS=0;                     # 如果要从头开始复制 就填0

            mysql> start slave;     # 开始同步主节点
            Query OK, 0 rows affected (0.00 sec)
            mysql> show slave status;  # 查看从节点状态
        ```

# 事务的ACID

- Atomicity 原子性：

    一个事务中的所有操作需要原子地执行，要么都成功，要么都不成功；不成功即会将已经执行的那一部分回滚，让一切都会到事务开始之前的样子。通过undolog来实现，如果事务执行不成功或者用户主动rollback，就会根据udolog的内容，将数据还原到事务开始时的样子。
- Consistency 一致性：

    在整个事务执行过程中，完全符合数据库的定义、约束等机制。在事务开始前后，数据库的完整性都不会被破坏。即这个其实是其他三个特性导致的结果。
- Isolation 隔离性：

    数据库允许多个并发事务同时对数据进行读写，不同级别的隔离性能够不同程度地解决多个事务并发执行时产生的数据不一致问题，从而保证并发事务在一定程度下互不影响。
- Durability 持久性：

    在事务提交之后，对数据做出的修改就是永久的，即使系统故障也不会丢失。通过redolog来保证。
  
# 隔离级别

我们知道数据库事务有着ACID的四个特性，其中I指的是Isolation隔离性，它描述的是对于正在进行中的多个事务，数据库有着不同隔离级别的实现，以解决并发事务之间的数据访问时可能出现的各种问题。

一般地，并发执行的事务之间如果不作任何隔离处理，那么会有以下问题：
1. 脏读  
一个进行中的事务读到了其他事务还未提交的变更。
2. 不可重复读
一个事务在前后多次对同一条数据进行查询，每次结果不一样（强调一条记录前后不一样，主要因为update和delete）
3. 幻读
一个事务前后使用相同的查询条件，每次查出来的记录数量不一致（强调记录的数量不一样，主要因为insert）
4. 写覆盖
两个事务先基于正确数据读出了一条记录，做出了不同的修改，然后先后提交，后提交的数据会把先提交数据进行覆盖（有点类似于并发售票场景下的超卖问题）

显然，要解决这些问题，会带来额外的控制逻辑，隔离得越彻底，开销越大、数据库性能越低。

在SQL的通用标准中，规定了四种隔离级别：
1. 读未提交 Read Uncommitted   可以读到其他事务还未提交的内容
2. 读已提交 Read Committed     只能读到其他事务中已经提交的内容，能够解决脏读问题
3. 可重复读 Repeataable Read   在一次事务中，前后多次读取同一条记录，保证结果一样，解决脏读、不可重复读 
4. 串行化   Serializable       将所有事务的执行串行化，能够解决所有并发事务问题

# LBCC和MVCC

注意到，上述的四个隔离级别是通用SQL规范中定义的，至于具体的DBMS使用何种技术，实现哪些隔离级别都要具体讨论。

而实现各种隔离级别的技术有很多种，最简单的就是对并发访问的数据加锁，这就是LBCC；还有基于时间戳、版本号的无锁的并发控制。

## LBCC（Lock Based Concurrency Control）

知识最传统和简单的实现方式，即对读、写操加上不同粒度、不同持续时间、不同性质的锁，来达到不同隔离级别。

LBCC中的锁从功能上分为，读锁（又叫共享锁Share Lock, S锁）、写锁（又叫排他锁Exclusive Lock, X锁）。

对于同一个对象，多个事务可以同时加S锁，当至少有一个S锁时，这个对象可读不可写；

对于同一个对象，至多只有一个事务可以加X锁，此时这个对象只能由本事务写，而其他事务不可读、不可写。

> LBCC是如何实现各个隔离级别的？
1. 读未提交

    上面有提到四种并发问题，其中「写覆盖」问题是该隔离级别需要解决的。

    对于事务的写操作，添加持续的X锁，直到事务提交才释放锁；
    
    对读操作不做任何锁处理。

2. 读已提交

    读已提交需要解决「写覆盖」、「脏读」问题。

    对于写操作，添加持续的X锁，直到事务提交才释放锁；

    对读操作，添加临时的S锁，读完之后就释放锁，而不必等到事务结束。

    >  因为某一行数据如果正在被一个事务修改且未提交，那么它上面一定有一把X锁，此时其他事务要读必须等到事务被提交后才能拿到S锁。

3. 可重复读

    RR需要解决「写覆盖」、「脏读」、「不可重复读」问题。

    对于写操作，添加持续的X锁，直到事务提交才释放锁；

    对读操作，添加持续的S锁，一直持续到事务结束才释放。

    >  事务中一旦开始读某一行数据，就会对其加上S锁持续到事务提交或者回滚，这就导致该事务持续过程中，其他事务没法拿到X锁去修改这行数据，以此保证本事务中对这一行数据的多次查询保持不变。
4. 串行化

    需要解决上述所有问题，即需要额外解决「幻读」问题。

    幻读产生的根本原因是其他事务插入了新的数据，要解决这个问题对存量数据加行级锁已经不起作用，必须引入表级锁（或者范围锁），当事务对一张表进行读写时，对整个表（或者本次事务将会访问到的一个范围）添加锁，不让其他事务插入。

---
## MVCC (Multiple Version Concurrency Control)

看似LBCC能够实现四种隔离级别，但是它只解决了并发的「读读」问题，并发的「读写」问题都没有解决，换言之，通过LBCC实现的后个隔离级别，都是读时不能写，写时不能读。

当数据库更新频率较高时，频繁的加锁以及读写之间的锁竞争会大大降低数据库的并发性能。

针对这种场景，多版本并发控制MVCC应运而生。

> 首先需要明确：在mysql的实现中，并不是有了MVCC就不使用锁了。mysql不同的引擎都有着各种各样的锁支持。
```sql
# 全局锁
FLUSH TABLES WITH READ LOCK;
UNLOCK TABLES;

# 表锁
LOCK TABLE t1 READ;   # 表级读锁
LOCK TABLE t2 WRITE;  # 表级写锁
UNLOCK TABLE;         # 解锁

# 行锁
对于InnoDB而言，会对UPDATE、DELETE、INSERT语句涉及到的数据集加X锁；对于普通的SELECT语句，不会施加任何锁。

# 行级共享锁
select * from xxx where id=1 LOCK IN SHARE MODE;  
update x set id = 2 where id = 1;       # 阻塞

# 行级排他锁
select * from xxx where id = 1 FOR UPDATE; # id=1这一行被加上写锁
select * from xxx where id = 1 FOR UPDATE; # 将阻塞住
update x set id = 2 where id = 1;          # 将阻塞住


# 对于MyIsam而言 没有事务的概念 它的所有写操作都会加上表级别的X锁，整体而言其中的读操作和写操作都是串行的。
```

- 当前读

    对于InnoDB引擎而言，如果一个select语句加上了FOR UPDATE关键字，那么它会试图对查询的这一部分数据添加X锁；于是这个读操作读到的必然是最新的数据（这部分数据此时此刻只被这一个事务访问）。
    
- 快照读

    在MVCC机制中，每一行数据都会有一个隐藏字段DB_ROLL_PTR，即回滚指针，可以将它理解为这一行数据的历史版本链表的头指针，每一个版本都存储着此时此刻该行数据在进行中的各个事务中的数据。

    每一行数据还会有一个隐藏字段DB_TRX_ID，即事务id，它记录这当前版本所对应的事务id（这个事务还在执行当中）。

    快照读指的就是，在RC和RR隔离级别下，不加FOR UPDATE关键字的SELECT查询。

    在这种查询下，所看到的数据类似于一个专属于该事务id的快照版本。

    具体地，在一个事务中，第一次执行快照读时，才会生成这个逻辑上的「快照」；另一方面，这一份「快照」针对的是整个MYSQL实例上的所有库、所有表中的所有数据，而不仅仅是第一次快照读所涉及到的那部分数据。
---
> 在描述MVCC之前，还要明确两个概念：redolog、read view
## undolog

redolog是为了实现回滚而产生的设计，其具体工作原理可以描述如下：

在一个事务中，当需要更新某一行记录时，会copy该行记录的当前值做出对应修改，并打上DB_TRX_ID的值记录，然后将这一行记录的指针更新到原记录的DB_ROLL_PTR上，相当于在链表头部插入一个节点。

随后将该行数据写入到undo buffer，在合适的时间点将buffer中内容刷新到磁盘上。

与redolog不同的地方在于，redolog是以单独的log文件形式存在的，而undolog是以行数据的形式写在ibd数据文件中。

> 理解： undolog就是InnoDB中每一行数据中DB_ROLL_PTR指针构成的一个版本链表，可以在链表中查到此时此刻正在进行中的多个事务里，该行记录的不同数值。
## read view

read view是一个事务id的列表，对于每一个事务而言，当它第一次执行SELECT语句时，就会生成一个read view，它记录着此时此刻系统里还未提交的事务id列表。

假设当前事务（隔离级别为RR）id为101，第一次SELECT某表的某行记录时，系统还有80~89,91~100号事务还未提交，于是本事务的read view就是[80,81,89, 91,..,99, 100]（不包括当前的事务id）。

于是InnoDB会查看词条记录的DB_TRX_ID，有以下几种情况：
- 值为79，小于当前read view的最小值，说明这行记录的值已经被提交了，所以可以直接用。
- 值为90，注意到此版本号介于read view的最大值和最小值之间，但是它并未出现在集合内部，说明已提交，可以访问，否则不可访问，需要沿着这行记录的DB_ROLL_PTR往回找，直到发现一个不在read view范围内的版本。
- 值为101，它比当前read view的所有版本都要高，说明它是本事务开启之后才发生的另一个事务所提交的值，当前事务也是不可访问的，也要沿着DB_ROLL_PTR往回找到一个版本号小于read view中最大版本的、未出现在read view中的版本。

> 注意到，在MVCC中，事务的版本号是一个单调递增的值，所以版本链中每一个节点的DB_TRX_ID是月往回找就越来越小的。 可以理解为read view就是当前事务在select过程中，不应该访问的那些版本号。

RC和RR这两种隔离级别实现的区别在于：
- RC中，每一次SELECT的时候都会重新生成read view
- RR中，自第一次SELECT生成read view之后，后续的select都会沿用这个read view，以此保证本次事务中针对某一行记录的多次查询结果都是一样的

## 解决幻读

首先，MySQL的InnoDB中RR的隔离级别真的解决了幻读问题吗？

这里需要明确，「幻读」的「读」到底是当前读，还是快照读。

- 如果前后都是快照读，那么基于MVCC机制，在不考虑当前事务自己INSERT的前提下，对于相同的查询条件，查出来的数据集肯定是不变的（因为其他事务插入的记录，其DB_TRX_ID大于当前事务的read view，是不可访问的）。
- 如果前后都是当前读，那么基于Next-key Lock（邻键锁），能够保证当前事务执行过程中其他事务无法插入新的数据，从而避免幻读。
- 如果在一个事务中，先快照读，再当前读，后者会查出来db里最新的值然后加上锁，这两次查询出来的数据集就可能不一样，即发生幻读。
---
在InnoDB中，RR隔离级别下：
- MVCC是解决了快照读的幻读现象
- 采用邻键锁(记录锁 + 间隙锁）解决了当前读下的幻读现象

## 意向锁
IX、IS锁，这是InnoDB为了加快所查询锁引入的机制，其本质是表锁。

如果某事务想要加表锁，那可以先检查这个表上是否有IX或者IS锁，如果有则说明表中某些记录上已经有X或者S锁了，当前事务加表锁就直接阻塞；如果没有意向锁，那就可以直接加锁成功。

如果没有意向锁的话，就需要检查表里每一条记录是否有行锁，效率低下。
# binlog、undolog、redolog