# 计算机网络

## TCP & UDP

## HTTP

- 响应码
  - 101：switching protocols 协议 upgrade 时 服务端会响应 101
  - 200：请求成功
  - 301：moved permanently 永久重定向 http 重定向到 https B 站。浏览器会缓存，之后的请求会直接访问重定向后的地址。
  - 302：found 临时重定向（与 307 类似） http 重定向到 https 知乎、百度。会改变 method，如 post 变成 get。
  - 304：自上次请求，未修改的文件。浏览器对于已缓存到本地静态资源进行请求，如果服务端返回 304，那么浏览器就会直接拿本地缓存，否则服务端就会返回更新后的资源。
  - 307：temporary redirect。可用于 http 到 https 的重定向，谷歌浏览器发现某网站在 HSTS(Http Strict Transport Security)
  - 400：请求错误 如 body 中传入 json 格式错误
  - 401： Unauthorized 未授权 未带 Authorization 的 header
  - 403： forbidden 禁止访问 服务器接收到了请求但是拒绝执行该任务
  - 404： 没有找到该资源 文件/接口不存在
  - 500：internal server error 系统内部未知错误
  - 502：Bad gateway. The server was acting as a gateway or proxy and received an invalid response from the upstream server. (应用层服务挂了，网关收不到响应)
  - 504：Gateway Timeout. The server was acting as a gateway or proxy and did not receive a timely response from the upstream server. （应用层服务超时，超过了 nginx 配置的最大响应时间）

## 浏览器缓存机制

- 强制缓存

  - 在资源有效期内，再次请求时，浏览器直接调用缓存，而不会向服务器发送请求，相关的 response header:

    `Expires: Mon, 25 Oct 2021 20:11:12 GMT`

    `Cache-Control: no-cache  /  max-age=315600` 前者：每次请求都需要向服务器校验资源新鲜度 后者：浏览器在一年内都不需要向服务器请求资源

- 协商缓存

  - 再次请求时，向服务器校验资源新鲜度，如果是新鲜的，服务端返回 304（但不返回资源本身），然后浏览器从缓存中复用。相关的 response header:

    `Last-Modified / If-Modified-Since/ Etag / If-None-Match`

## HTTP2

HTTP 1.1 存在的问题：

- TCP 连接数量限制。不同浏览器对同一个域名至多只能同时创建 6~8 个 TCP 连接，于是引入了`域名分片`技术，将服务端资源放在不同子域名下，这样就可以打破单个域名的 TCP 连接数量限制。但是如此技术滥用也会带来问题，即 TCP 连接创建本身就需要经过 DNS 查询、三次握手、慢启动等，对于客户端的 CPU 和内存、服务端的网络带宽等资源都会带来很大的压力。
- 一个 TCP 连接一次只能处理一个请求和响应，浏览器通常是按照 FIFO 原则处理请求，如此可能会因为一个长时间未结束的请求而阻塞后续的请求。
- Header 内容非常多，但是每次请求时 header 其实不会有很大的变化，没有相对应的压缩传输优化方案。
- 明文传输不安全。

HTTP 2.0 的优势

- 二进制分帧层（Binary Framing Layer）

  帧是数据传输的最小单位，以二进制传输代替原本的明文传输，原本的报文消息被划分为更小的数据帧。

- 多路复用（Multiplexing）

  在一个 TCP 连接上，可以不断地向服务器发送帧，每帧的 stream identifier 表明了这一帧属于哪个 stream，服务端在接收后根据 stream identifier 来拼接每个流的所有数据帧，从而组成完整的报文内容。实现了单个连接上多个请求-响应的并行，解决了线头阻塞的问题，减少了 TCP 连接数量和 TCP 连接慢启动而造成的问题。

- 服务端推送（Server Push）

  浏览器发送一个请求，服务器主动向浏览器推送这个请求相关的资源，这样浏览器就不用发起后续请求。

- Header 压缩（HPACK）
  使用 HPACK 算法来压缩首部内容。

## gzip 压缩

gzip 采用了 Deflate（一种结合了 LZ77 和哈弗曼编码的无损数据压缩算法）算法，重复度越高的文件可压缩的空间越大，所以常被用于 HTTP 文件传输中，如 JS、CSS 等，但一般不会压缩图片。

通常情况下，不要对图片、PDF 等其他二进制格式文件使用 gzip，因为他们本身就是经过压缩的，使用 gzip 不仅不会带来更多的压缩效果，反而可能使得文件变得更大。

在 HTTP response 中，用 Content-Encoding 指明文件按照 gzip 格式返回，浏览器则会进行解压缩。gzip 一般配在反向代理那一层，如 nginx。

```nginx
gzip            on;
gzip_min_length 1000;
gzip_proxied    expired no-cache no-store private auth;
gzip_types      text/plain application/xml;
```

LZ77 由 Jacob Ziv 和 Abraham Lempel 于 1977 年提出，于是命名为 LZ77。

其基本思想是：如果一段文本中有两块完全相同的内容，那么把第二段替换成描述第一段所在位置的信息，只要这段描述信息比重复内容本身要更短，那么就可以达到压缩的效果。

哈夫曼编码树：将文件中出现的一定位长的值看做是一个符号，进而统计文件中所有符号的出现频率，依照此频率来构建哈弗曼编码树，最后使用哈夫曼编码来替换原文内容，达到压缩效果。（哈弗曼编码树中，符号出现的频率越高其编码就越短，且不可能出现编码前缀的现象）。

## HTTPS

针对 HTTP 协议明文传输的缺点，早在 1994 年 Netscape 公司在推出网景导航者时，就引入了 HTTPS 协议，以 SSL 进行加密。
TLS（transport layer security）以及其前身 SSL（secure sockets layer），均是一种运输层的安全协议，旨在为互联网通信提供安全以及数据完整性保障。

### TLS 握手流程

Client -> Server: Client hello (TLS 版本、客户端支持的加密套件清单、第一随机数)

Server -> Client: Server hello (TLS 版本、服务端选择的加密套件、第二随机数)

Server -> Client: Certificate (该网站在某 CA 注册的证书) 浏览器拿到证书之后根据自己的信任列表来判断当前网站是否可信

Server -> Client: Server key exchange (发送 public key 给客户端)

Server -> Client: Server hello done

Client -> Server: Client key exchange （生成第三个随机数，又称为预主秘钥，通过 public key 加密之后 发给服务端）

Client -> Server: change cipher spec 告知服务器，往后的数据就开始通过商议好的算法和秘钥来加密。

Client -> Server: encrypted handshake message 告知服务器，客户端侧 TLS 协商完成，开始加密。

Server -> Client: encrypted handshake message 告知客户端，服务端侧 TLS 协商完成，开始加密。

注意到，最终用于 HTTPS 报文内容加密的秘钥，是通过第一随机数、第二随机数、预主秘钥 这三个随机数经由加密套件计算得来的，浏览器和客户端加密解密的过程都是对称加密。

而客户端使用证书中的 public key 来加密预主秘钥、服务端用私钥解密预主秘钥的过程，才是非对称加密。

# mysql

- 事务的特性 ACID

  - Atomicity 原子性：一个事务中的所有操作需要原子地执行，要么都成功，要么都不成功；不成功即会将已经执行的那一部分回滚，让一切都会到事务开始之前的样子。
  - Consistency 一致性：在事务开始前后，数据库的完整性都不会被破坏，即在整个事务执行过程中，完全符合数据库的约束、触发器等机制。
  - Isolation 隔离性：数据库允许多个并发事务同时对数据进行读写，不同级别的隔离性能够不同程度地解决多个事务并发执行时产生的数据不一致问题。
    - Read uncommited - 读未提交 A 事务可以读到 B 事务还未提交的修改。
    - Read commited - 读已提交 A 事务只可以读到 B 事务已经提交的修改。
    - reapeatable read - 可重复读 A 事务在进行过程中前后多次读通一条数据，保持结果完全一样。
    - serilizable - 串行化 A、B 事务完全各自隔离，并发执行完两个事务之后，效果跟 A、B 先后执行完全一致。
  - Durability 持久性：在事务提交之后，对数据做出的修改就是永久的，即使系统故障也不会丢失。

- 事务并发执行可能出现的问题

  - 脏读 事务 A 在执行过程中，读取到了 B 还未提交的内容。 Read commited 级别能避免该现象，但依旧会有幻读和不可重复读。
  - 幻读 事务 A 在执行过程中，由于事务 B 的插入或者删除操作，前后两次读取的记录数量不一样，就像出现了幻觉一样，刚刚明明已经全都 update 了，现在又多了两条没更新的数据。
  - 不可重复度 事务 A 在执行过程中，先后两次依赖某些记录的值，但是发现这些值前后两次值不一样。

  脏读强调的是读取到其他事务做出的、还没有提交的修改。

  幻读强调的是因为其他事务插入或者修改，导致前后读取到的数据量不一样。

  不可重复度强调的是因为其他事务的更新，导致某一条记录前后读取到的值不一样。

  read commited 可以避免脏读的出现。（锁定正在读取的行）

  repeatable read 可以避免不可重复度的出现。 （锁定所读取的所有行）

  serilizable 可以避免以上三种问题的出现。（锁表）

- InnoDB 和 MyISAM 的区别

  - MyISAM :

    - 不支持事务，每次查询都是原子的。
    - 只支持表级锁，每次操作都会对整个表加锁。
    - 会存储总行数
    - 每一张表有三个文件：索引文件、表结构文件、数据文件
    - 采用非聚集索引，即索引节点本身不存储数据，而是存储数据文件的指针。

  - InnoDB:
    - 支持 ACID 的事务和四种隔离级别（默认是 Repeatable read）
    - 支持行级锁和外键约束，仅此支持并发写。
    - 不会存储总行数
    - 主键采用聚集索引，即索引节点本身就会数据，而辅索引节点中存储的是主键的值。
    - 最好采用自增主键，防止插入数据时，为维持 B+数的结构而对索引文件产生大调整。

- char 与 varchar 的区别

  - char 类型在存储时长度是固定的，当实际内容长度不足时，引擎会采用空格填充到指定长度。
  - varchar 类型在存储时，存的是实际长度的内容，且会有字节专门用来记录长度。

- unix 时间戳和 mysql 时间之间转换

  UNIX_TIMESTAMP() --- mysql 时间->unix 时间戳

  FROM_UNIXTIME() --- unix 时间戳->mysql 时间

- BLOB 和 TEXT 的区别
  - BLOB 是一个二进制对象，存储的是二进制数据， 而 TEXT 存的是非二进制字符串
  - TEXT 大小写不明感，而 BLOB 排序和比较大小以大小写敏感的方式执行
  - TEXT 需要指定字符集，而 BLOB 不需要。
  - TEXT 只能存储纯文本，而 BLOB 可以存储图片。
- 可以创建多少个列？可以创建多少个索引？一个索引最多包含多少列？一个索引最大多少字节？

  - innoDB: 最多创建 1017 列, 最多 64 个二级索引, 单个索引最多包含 16 列, 索引最大长度 767 字节(其实行格式为 REDUNDANT,COMPACT 最高为 767 字节,但行格式为 DYNAMIC,COMPRESSED 最高可达为 3072 字节), 行大小最大 65536 字节
  - mysiam: 最多 4096 列, 最多 64 个二级索引, 单个索引最多包含 16 列, 索引最大长度 1000 字节, 行大小最大 65536 字节

- NOW()和 CURRENT_DATE()

  NOW() --- 显示当前的年份、月份、日期、小时、分钟、秒
  CURRENT_DATE() --- 显示当前的年份、月份、日期

- MySQL 支持事务嘛？
  在默认设置下，mysql 是 autocommit 模式的，即所有数据库更新操作都会自动 commit。如果没有显式地开启事务和提交，那么默认是不支持事务的。

  如果表类型是 innoDB tables，那么就可以通过 set autocommit=0 来切换到非 autocommit 模式，该模式下必须使用 commit 来提交或者用 rollback 来回滚更新。

- 记录货币用什么字段类型

  DECIMAL 类型， 例如 `salary DECIMAL(9, 2)`，其中 9 表示 precision，即用于存储值的总的数位长度，2 表示小数点后的位数，该字段可以存储值的范围是`-9999999.99 ~ 9999999.99`

- 数据库设计原则

  - 设计良好的数据库结构，允许部分数据冗余，尽量避免 join 查询，提高效率。
  - 选择合适的表字段来建立索引，尽可能多考虑到后续的业务拓展性。
  - mysql 采用主从架构，读写分离。
  - 当单表规模巨大时，按照一定规则进行水平分表，以提高查询效率（主键哈希、时间分片等）。
  - 添加缓存机制，如 redis，对多读少些场景下的数据进行缓存。
  - 业务逻辑中 sql 优化，避免复杂、低效的查询语句。

- 分库分表

  - 好处
    - 解决数据库本身的瓶颈，如 too many connections，这是数据库设置的最大连接数太小，mysql 默认是 100，最大可以设置到 16384.
    - 解决系统本身的 IO、网络、CPU 瓶颈。
  - 何时分库分表
    - 能不分就不分，当数据量并没有达到瓶颈时，过早的分表，反而会增加业务的复杂性，得不偿失。
    - mysql 在执行 DDL 的时候会锁表，这段时间里业务都不能读取这张表，所以当一张表的数据量特别大且需要经常更新表结构时，就可以采用水平切分。
    - 考虑到安全和可用性，垂直切分可以从业务层面将不同数据隔离开，每个业务只关注自己需要的那部分数据；水平切分可以一定程度提高系统的可用性，因为每一张表只负责一部分业务的数据，不会因为个别库挂了而影响所有用户。
  - 不到万不得已，不要轻易分库分表，避免过度设计和过早优化。在实行分库分表之前，需要先去做力所能及的优化工作，例如硬件升级、网络升级、读写分离等，只有当单标数据量达到瓶颈时才考虑分库分表。
  - 垂直分表
    - 基于字段，大表拆成多个小表。对于那些字段很多的大表，将其中不常用或者数据较大、长度较长的字段拆到拓展表里；将访问频次高、更加重要的信息单独放到一张表里。
    - 为什么大字段的 IO 效率低下？
      - 数据本身庞大，读取开销大
      - 数据库以页为单位存储在磁盘里，查询时是以页为单位的，一页里的数据行越多，整体查询性能就越好，单表中字段越大，一页所能存储的行数就越少。
      - 数据库以行为单位把数据加载到内存中，若表中字段的长度短且访问频率高，那么就能增加内存的命中率，减少磁盘的 IO，提升读数据的性能。
  - 水平分表
    - 将数据进行划分，把一张表里的数据分散到若干张表里去，解决单表数据量过大的问题。
    - 水平分表需要选择合适的分片键和分片策略，并与业务深度配合；避免数据热点和访问不均衡、避免二次扩容难度大。

- 索引失效

  模型数空运最快

  - 模： 模糊，使用 like 进行模糊查询的时候，以百分号开头，所以就会失效。
  - 型：产生数据类型转换，索引也会失效（特别注意 varchar 类型的字段编码，两张表同名字段编码不一致也可能产生类型转换从而导致索引失效）。
  - 数：函数，对索引字段使用内部函数，索引也会失效。
  - 空：NULL 值，索引不存储空值，在不同数据库的不同引擎中，可能因为字段中的 NULL 而引发索引失效。
  - 运：运算，对索引列进行加加减乘除等运算，都会导致索引失效。
  - 最：最左原则，在复合索引中，如果不能按照顺序从左至少命中一个索引列，那么剩下的索引列即使在复合索引范围内，也无法命中。
  - 快：全表扫描更快。数据库再执行一条查询语句之前会去分析并估算各个子查询的开销，如果按照索引查询的开销估算比全表扫描还高，那么就会直接全表扫描。

- 实践中的 MySQL 优化
  - 1、SQL 语句和索引的优化
  - 2、数据库表结构的优化（冗余、拆分）
  - 3、系统配置的优化（连接数配置、缓存设置）
  - 4、硬件的优化（IO、网络带宽、CPU）

# redis

- 为什么快

  - redis 是基于内存存储实现的数据库，相比于数据存在磁盘的数据库，可以节省掉磁盘 IO 的开销。
  - 高效的数据结构
    - String -> 动态字符串
    - List -> 双端链表、压缩链表
    - Hash -> 压缩链表、字典
    - SET -> 字典
    - Zset -> 压缩链表、跳跃表
  - 合理的线程模型

    - 单线程模型，避免上下文切换。

    redis 的单线程，指的是 redis 的网络 IO 和键值对读写是由一个线程来完成的，但是其他功能如持久化、异步删除、集群数据同步等，都是有其他线程参与的。

    单线程模型避免了 CPU 不必要的上下文切换和竞争锁的消耗，但也正因为是单线程，如果某个命令执行时间过长（如 hgetall）则会造成阻塞。redis 是面向快速执行场景的内存数据库，所以要慎用 lrange、hgetall 等命令。

  - IO 多路复用

  IO: 网络 I/O 多路：多个网络连接 复用：复用同一个线程。
  IO 多路复用其实就是一种同步 IO 模型，它实现了一个线程可以监听多个文件句柄，一旦某个文件句柄就绪，就能够通知应用程序对其进行相应的读写操作。
  IO 多路复用技术可以让单个线程高效地处理多个连接请求，而 redis 使用 epoll 作为 IO 多路复用技术的实现。

  - 虚拟内存机制

  redis 自己构建了 VM 机制，将不经常访问的数据从内存交换到磁盘中，从而腾出宝贵的内存空间来存储需要被访问的热数据。

- 持久化策略
  - AOF append only file，定时将操作日志追加到 AOF 文件中，重启时通过重放这些操作来恢复 redis 的状态。
  - RDB redis database，定时快照，能够快速恢复到某一个时刻的状态，但是数据一致性和完整性受到限制。
- 雪崩、击穿、穿透
  - 雪崩： 大量缓存数据同时过期，或者 redis 故障，导致大量读请求打到 db 上
    - 均匀设置过期时间，避免同时过期
    - 更新缓存时加互斥锁，保证同时至多只有一个应用在构建缓存
    - 双 key 策略，主 key 会过期，备 key 永久有效，当发现主 key 过期时返回备 key 的值，然后再更新主、备 key 的值。
    - 专门开启缓存更新服务，通过定时任务/消息队列等方式主动更新缓存，对于业务来说，认为缓存永久有效。
  - 击穿：热点数据缓存过期，大量请求直接打到 db
    - 缓存击穿类似于雪崩问题，可以采用一样的策略来避免
  - 穿透：用户需要访问的数据既不在缓存里，也不在 db 里，即使 db 能够抗住压力，但是依旧没有目标数据来重新构建缓存，数据请求始终无法被满足。
    - 限制非法请求（请求参数是否有非法值？字段是否存在？）。
    - 缓存空值或默认值（业务发现出现了穿透现象，及时给这些 key 设置默认值）。
    - 采用布隆过滤器来快速判断请求的目标数据是否存在，避免直接查询 db。
- redis 的应用场景
  - 缓存
  - 消息队列 （pubsub、轮询） 没有 ACK、可能丢消息、需要做 redis 持久化配置
  - 分布式锁
  - 分布式 websocket 服务器
  - 限流 （漏桶、令牌桶）

# 操作系统

# linux

# docker

# k8s

它是一个为容器化应用提供集群部署和管理的开源工具，由 google 开发。

kubenatees 这个名字源于希腊语，本意为“舵手”或者“飞行员”。

k8s 这个缩写中的 8 表示 k 和 s 之间有八个字母。

主要特性：

- 高可用、不宕机、自动灾难恢复
- 灰度更新，不影响业务正常运转
- 一键回滚到历史版本
- 方便的伸缩拓展、提供负载均衡
- 拥有完善的生态社区

## 部署方式

- 传统部署方式

  应用直接部署在物理机上，机器资源分配不好控制，出现 bug 时，机器的大部分资源可能全被某一个应用占用，导致其他应用无法正常运行，无法做到应用隔离。

- 虚拟机部署

  在单个物理机上运行多个虚拟机，每个虚拟机都拥有完整的操作系统，不同虚拟机之间的应用完全隔离，但是这样性能损耗非常大。

- 容器部署

  所有容器共享主机的系统，相当于一个个轻量级的虚拟机，性能损耗小、资源隔离，CPU 和内存可以按需分配。

## 什么时候需要 kubenates？

当应用只是抛在一台机器上时，docker + docker-compose 就足以满足需求；

当应用需要跑在三四台机器上时，依旧可以为每台机器单独配置运行环境， 再对各台机器做一个负载均衡。

但当应用访问数量不断增加，服务器拓展到几十台、上百台甚至成千上万台时，添加/裁撤机器、更新应用、版本回滚，都会变得非常麻烦且混乱。

kubenates 就可以提供集中式的集群机器与应用管理，加机器、版本升级、版本回滚，统统都是一条命令搞定的事，不停机的灰度更新也能够确保高可用、高性能、高拓展。

## k8s 架构

- master

  主节点，控制平台，不需要很高性能，不跑任务，通常一个就够了，也可以开多个 master 来提高集群的可用度。

- worker

  工作节点，可以是虚拟机或者物理机，任务都运行在 workder 节点上，机器的性能需要好一些；通常都有多个，可以不断增加机器来扩大集群；每个工作节点由主节点管理。

- 重要概念 pod

  豆荚，k8s 调度、管理的最小单位，一个 pod 内可以包含一个或多个容器，每一个 pod 都有自己的虚拟 ip。

  一个工作节点可以有多个 pod，主节点会考虑工作节点的负载而自动将 pod 调度到合适的工作节点上。

- 基础操作

  - 部署一个 deployment kubectl apply -f ./test-k8s.yaml

  ```yaml
    apiVersion: apps/v1
    kind: Deployment
    metadata:
    # 部署名字
    name: test-k8s
    spec:
    replicas: 2
    # 用来查找关联的 Pod，所有标签都匹配才行
    selector:
        matchLabels:
        app: test-k8s
    # 定义 Pod 相关数据
    template:
        metadata:
        labels:
            app: test-k8s
        spec:
        # 定义容器，可以多个
        containers:
        - name: test-k8s # 容器名字
            image: ccr.ccs.tencentyun.com/k8s-tutorial/test-k8s:v1 # 镜像
  ```

  - deployment 扩容

    `kubectl scale deployment/test-k8s --replicas=4`

  - 临时将 pod 的端口暴露并映射到本机端口

    `kubectl port-forward test-k8s-68bb74d654-8hq7v 8080:8080`

  - 查看 deployment 的历史版本

    `kubectl rollout history deployment/test-k8s`

  - 回退到上一个版本 (可以指定回退到哪一个版本)

    `kuebctl rollout undo deployment/test-k8s  [--to-revision=1]`

  - 删除部署

    `kubectl delete deployment/test-k8s`

  - 重新部署（对 yaml 不作任何改变）

    `kubectl rollout restart deployment/test-k8s`

以上，通过 port-forward 的方式仅能暴露单个 pod 的服务端口，在集群内部没有负载均衡和名字服务，于是有必要引入 service。

- 创建 service

  - Service 通过 label 关联对应的 Pod
  - Servcie 生命周期不跟 Pod 绑定，不会因为 Pod 重创改变 IP
  - 提供了负载均衡功能，自动转发流量到不同 Pod
  - 可对集群外部提供访问端口
  - 集群内部可通过服务名字访问

    ```yaml
    apiVersion: v1
    kind: Service
    metadata:
      name: test-k8s
    spec:
      selector:
        app: test-k8s
      type: ClusterIP
      ports:
        - port: 8080 # 本 Service 的端口
          targetPort: 8080 # 容器端口
    ```

    `kubectl apply -f service.yaml`

- service 的几种类型

  - Cluster IP 仅能在集群内部访问
  - NodePort 占用 svc 所在 work 节点的一个端口 将对该节点本端口的请求转发到这个 svc 上
  - LoadBalancer 需要引入第三方服务商的负载均衡器，会引入一个额外的 External-IP 来暴露本 svc
  - Headless

- 集群内部访问 svc

  - 通过 clusterIp 访问指定的 pod

  ```javascript
  georgayang@GEORGAYANG-MB1 k8s_learning % kubectl get po -n ld -owide
  NAME                        READY   STATUS    RESTARTS      AGE   IP           NODE       NOMINATED NODE   READINESS GATES
  test-k8s-68bb74d654-hn2xv   1/1     Running   1 (19h ago)   43h   172.18.0.2   minikube   <none>           <none>
  test-k8s-68bb74d654-z9fvb   1/1     Running   1 (19h ago)   43h   172.18.0.6   minikube   <none>           <none>

  georgayang@GEORGAYANG-MB1 k8s_learning % kubectl exec -it -n ld test-k8s-68bb74d654-hn2xv -- bash

  root@test-k8s-68bb74d654-hn2xv:/app# curl 'http://172.18.0.6:8080/hello/123123123'
  hello 123123123

  IP lo172.18.0.6, hostname: test-k8s-68bb74d654-z9fvb
  ```

  - 通过 k8s 的名字服务，访问 svc，由 k8s 来负载均衡

  ```javascript
  root@test-k8s-68bb74d654-hn2xv:/app# curl 'http://test-k8:8080/hello/123123123'
  ```

- 向集群外部暴露 svc

  - port-forward 将本机请求转发到 svc 上 (临时方案)

  ```javascript
  georgayang@GEORGAYANG-MB1 k8s_learning % kubectl port-forward svc/test-k8s -n ld 8080:8080
  ```

  - svc 类型改为 NodePort 绑定 nodePort

  ```javascript
  apiVersion: v1
  kind: Service
  metadata:
    name: test-k8s
  spec:
    selector:
      app: test-k8s
    # 默认 ClusterIP 集群内可访问，NodePort 节点可访问，LoadBalancer 负载均衡模式（需要负载均衡器才可用）
    type: NodePort
    ports:
      - port: 8080        # 本 Service 的端口
        targetPort: 8080  # 容器端口
        nodePort: 31000   # 节点端口，范围固定 30000 ~ 32767

  kubectl apply -f ./svc.yaml -n ld

  接下来就可以通过节点的31000端口访问到这个svc（在本例中需要进入到minikube的容器里去）
  ```

## StatefulSet

Deployment 可以任意扩充 pod，每一个 pod 在使用起来都是一样的，不管请求 lb 到哪个 pod，业务都能正常运行。

StatefulSet 是用来管理有状态应用的，如数据库、redis。

StatefulSet 会固定每个 pod 的名字。

- 创建一个 StatefulSet 类型的 mongodb

  ```javascript
  apiVersion: apps/v1
  kind: StatefulSet
  metadata:
    name: mongodb
  spec:
    serviceName: mongodb
    replicas: 3
    selector:
      matchLabels:
        app: mongodb
    template:
      metadata:
        labels:
          app: mongodb
      spec:
        containers:
          - name: mongo
            image: mongo:4.4
            # IfNotPresent 仅本地没有镜像时才远程拉，Always 永远都是从远程拉，Never 永远只用本地镜像，本地没有则报错
            imagePullPolicy: IfNotPresent
  ---
  apiVersion: v1
  kind: Service
  metadata:
    name: mongodb
  spec:
    selector:
      app: mongodb
    type: ClusterIP
    # HeadLess
    clusterIP: None # 这里设置为None 就不会给这个svc分配clusterIP
    ports:
      - port: 27017
        targetPort: 27017

  ```

- StatefulSet 的特性
  - service 的 clusterIP 是空的
  - POD 的名字是固定的，创建是顺序的、销毁是逆序的
  - POD 重建的时候名字不变，但是 IP 会变，所以业务里不能用 IP 来访问。

# git

# 后端基础

1. 生产环境接口报错，如何排查
   - 根据反馈问题的操作路径，看测试环境是否能够复现，如果可以则可以快速地定位并修复问题
   - 如果测试环境无法复现，则需要根据生产环境的错误编码/异常堆栈信息进行异常服务 or 接口的定位
   - 如果异常信息不足以定位问题，或者请求链路非常长、涉及到很多服务，则需要结合链路追踪工具和请求的 requestId，去定位上下游服务的日志，从中找到异常环节。
   - 最怕的是接口本身没有报错，但是业务方/客户反馈数据异常，这种就需要结合生产环境的数据库、上下游服务、请求入参，进行人肉 debug。
2. 后端敏感数据在生产环境如何配置
   - CI/CD 流程中从配置中心拉取服务的 config 文件，通过第三方工具如 nodejs 中的 dotenv 将 config 文件以环境变量的形式注入到服务进程中。
   - 通过 k8s 的 configMap 将配置文件注入到容器指定位置，再通过代码读取文件的内容并加载到内存中。
3. 如何实现一个分布式锁
   - 当多个服务需要同时访问相同资源时，可能会产生并发读写相关的问题，所以需要互斥地访问该资源，此时需要引入分布式锁
   - 分布式锁共有两个关键点，① 分布式 ② 锁
   - ① 即整个分布式系统中，需要获得锁的服务需要全部能够访问到发放锁的中介，就比如 redis、zookeeper
   - ② 锁就必须要保证请求者能够正确地、互斥地占有锁
     - 可以通过 redis 实现，在旧版本的 redis 中，set 指令不支持同时传入 EX 和 NX 所以需要使用 setNX 指令写入一个 key，然后再 expire 这个 key，为了保证原子性地执行这两个指令，需要引入 lua 脚本，通过 eval()函数来原子地执行这两个命令。
     - 后来 set 指令开始支持同时传入 EX 和 NX 标志，即可以原子地判断 key 是否存在、不存在则写入、写入完了设置过期时间，就不用再引入 lua 脚本了。
     - 注意到，为了确保锁在未被正常释放时不会永久被持有，所以锁 key 是有过期时间的。
     - 另一方面，为了保证锁不会错误地被非持有者释放，需要在加锁时生成一个 token 并作为 key 的 value 进行存储，加锁者在释放锁时传入这个 value，才能够成功的将该 key 删除，即释放锁。那么释放锁就分为三步 get -> 比较值 -> del，而这个过程同样需要原子地执行，所以依然需要通过 lua 脚本来执行。
4. websocket 服务多节点部署会遇到什么问题，如何解决？
   1. 广播问题：单个节点需要给所有的客户端广播消息，而它本身只维护了一部分 ws 连接。
      - 解决方案：引入 redis 或者 kafka 等所有节点都能触达的一个中介。
        - 需要广播时任意请求一个节点，该节点向 redis/kafka 中推送该条广播消息
        - 所有节点订阅 redis/kafka 的广播消息
        - 当 redis/kafka 中有广播消息请求时，向所有订阅了的节点 push 消息。
        - 在上述提到的订阅/发布模式中，采用 redis 的 pubsub 是一种非常轻量级的实现方案，也有很多成熟的封装，API 简单易用。
   2. 单推问题：当业务侧需要给某个在线客户端推送消息时，无法确定该客户端的 ws 连接在哪个节点上。
      - 解决方案：在建立 ws 连接之后，客户端主动向服务端上报一个连接信息数据包，将能够标识该用户的 user_id 与服务端当前 ws 连接的句柄进行映射，同时将此信息存至 redis，于是服务端就可以根据 user_id 去 redis 来查询该用户当前的 ws 连接处在哪个节点上，再向该节点发送消息。
5. 如何进行接口压力测试

   Jmeter 等其他压测工具，针对指定接口，编写前后钩子来构造/恢复测试的业务场景或数据，配置不同的线程数、循环次数，来构造不同的并发程度。

   通过观察分析 QPS、平均耗时、错误率等信息来判定接口性能并进行后续优化。

6. 接口如何限流

   1. 漏桶算法： 维护一个会匀速漏水的 bucket，新的请求在 bucket 没有满之前可以顺利入桶，当新的请求会导致桶溢出时，则拒绝该请求。

      - 具体实现：使用 redis 计数器实现。

        1. 计数器初始为 0 并设置过期时间。
        2. 当 API 被调用时检查计数器的值，如果未达上限，则计数器加一并执行请求；如果达到上限，则拒绝当前请求；如果计数器的 key 不存在，则重新创建该计数器，并执行本次请求。

      - 存在的问题：

      1. 这里的实现其实不像是一个会漏水的桶，而是每隔一段时间把桶倒空，这样可能会在上一个周期的后半段时间涌入 max - 1 的请求，又在下一个周期的前半段时间涌入 max 的请求，那么 在一个时间窗口内，实际上成功处理了 2 \* max - 1 个请求，这超过了既定的频率。
      2. 可以把计数器改为一个队列，该队列维护指定时间范围内的请求时间戳。当新的请求到来时，加入该队列，并且筛选这个队列，将那些时间戳 + 时间范围 < 当前时间戳的那些记录删掉；此时，判断队列的长度，如果大于限定频率，则拒绝本次请求，否则执行请求。
      3. 当检查桶时发现 key 不存在，则需要 set 这个 key 并且设置其 expire 时间，这两个执行需要原子地执行，否则可能有并发错误，可以通过 set 指令的 EX、NX 标志来解决这个问题，也可以用 lua 脚本保证原子性。

   2. 令牌桶算法：维护一个令牌池，当池不满时，会议恒定速率往其中加令牌；请求到达时，如果当前还有令牌，那么就会减少一个令牌并立刻执行请求；如果没有令牌了，那就拒绝请求。
   3. 此二者的区别： 漏桶算法类似于一个有 buffer 的消息队列，所有消息会被匀速地消费，它能强行限制请求被执行的速率；而令牌桶瞬时到达多个请求时，只要令牌充足，所有请求都会被立刻执行，它无法限制时间区间内的瞬时速率，从另一个角度想，它其实又能够支持短时间内的突发流量，也并不是一个坏事。

7. Dockerfile 构建镜像成功，但是 pod 起不来

   在构建镜像时，如果 RUN 中的进程返回了非 0 的 exitcode，那么就会构建失败。 而在 nodejs 中，如果 await 一个 function 时出现了异常，它会是一个 UnhandledPromiseRejectionWarning，如果这个异常最终导致了进程的结束，那么 exitCcode 会是 0，所以我们在服务最外层的异常处理中，最好手动地 process.exit(1)，尽可能在编译时就将问题暴露出来。

8. JWT 原理

   JWT(JSON Web Token)由三部分组成：Header、Payload、Signature。其中 Header 和 Payload 都是 base64 编码之后的字符串，它们是可以被解码的，所以不允许存储任何隐私数据；Signature 是通过非对称加密算法对前两段的签名，能够保证前两段中存储的数据不被篡改。

   - Header 段存储了本 JWT 的非对称加密算法名和类型
   - Payload 段是一些`registered Claim`字段，比较重要的有
     - `exp --- jwt过期时间`
     - `iat --- jwt创建时间`
     - `user_id --- 用户唯一标识`
   - Signature 是根据 Header、Payload 和存储在服务端的 secretKey 生成的签名。
   - JWT = base64(Header) + '.' + base64(Payload) + '.' + HASH(secretKey, base64(Header) + '.' + base64(Payload))

9. 如何进行代码质量检测

   圈复杂度（Circle complexity）表述了代码的复杂程度，其本质是覆盖所有代码逻辑所需要用到的最少的测试用例数，越高则越不好维护。（可以理解为代码逻辑的分支复杂程度）

10. 单点登录 SSO 单点登录流程
    `https://images2015.cnblogs.com/blog/797930/201612/797930-20161203152650974-276822362.png`
11. 获取客户端的 IP
    1. 如果有 x-forward-for 请求头，取其中的第一个 IP
    2. 否则取 socket.remoteAddr
12. cors 相关的响应头

    cors 是用来解决跨域 HTTP 请求问题的一种机制。

    - 跨域问题：由浏览器的同源策略引发， 它限制了来自一个 origin 的文档或者它所加载的脚本向另一个源请求 HTTP 资源，除非另一个源的响应报文中包含了正确的 CORS 头。
    - `源`由 URL 的协议、host、port 来确定，只有当这三者都相同时，才会被浏览器当做是同一个源。

    `Access-Control-Allow-Origin`

    `Access-Control-Allow-Methods`

    `Access-Control-Allow-Headers`

    - 浏览器跨域访问资源流程
      - 如果是 POST、GET、HEAD 中的 method，且 header 中的信息不超过 accept、Accept-Languwage、Content-Language、Content-type（且值为 text/plain、multipart/form-data、application/x-www-form-urlencoded 之一）时，被认为是简单请求，不会发送预检请求，跨域的那个源的服务端可以通过 Access-Control-Allow-Origin 这个头来告诉浏览器，这个资源是否允许被当前 origin 跨域访问。
      - 否则需要发送一个 OPTION 类型的请求进行预检，当服务端正确返回了 Access-Control-Request-Origin 、还会通过 Access-Conrtol-Allow-Methods 说明正式请求该使用的方法、XXXX-Headers 说明将接受的自定义 header 字段、XXX-Max-Age 说明该预检结果能被缓存多久。

# rpc 框架

- 客户端
  - 服务发现
  - 服务路由
  - 负载均衡
  - 熔断
- 服务端
  - 服务注册

公有云 tke -
tcs
政务云两套
合理用药 - 云杉 https://thcloud.woa.com/index?r=%2Fservice%2Findex&query=%257B%2522_q%2522%253A%2522%25255B%25257B%252522alias%252522%25253A%252522Diagnosis_UserManageServer%252522%25252C%252522name%252522%25253A%252522ServiceDetailList%252522%25252C%252522query%252522%25253A%25257B%252522appName%252522%25253A%252522Diagnosis%252522%25252C%252522serverName%252522%25253A%252522UserManageServer%252522%25257D%25252C%252522params%252522%25253A%25257B%252522appName%252522%25253A%252522Diagnosis%252522%25252C%252522serverName%252522%25253A%252522UserManageServer%252522%25257D%25252C%252522closable%252522%25253Atrue%25252C%252522id%252522%25253A%252522ServiceDetailList_Diagnosis_UserManageServer%252522%25252C%252522actived%252522%25253Atrue%25252C%252522class%252522%25253A%252522%252522%25252C%252522isCache%252522%25253Atrue%25257D%25255D%2522%252C%2522owner%2522%253A%2522georgayang%2522%252C%2522useLike%2522%253Atrue%252C%2522codingStatus%2522%253A%255B%255D%257D

家医 -

校验 token
