# 流调
深圳市流行病学调查处置系统，疫情期间用于各疾控对本区当日上报阳性病例的流行病学调查。

核心功能包括信息的录入、流调任务的部署分发、智能语音电话、跨区任务协同、流调报告生成、驾驶舱数据总览等。

我主要参与的功能模块包括：统一用户管理中心、智能语音电话、数据结构改造优化、流调报告生成器、站内信及通知模块。

- 统一用户管理中心

    这是一个与业务解耦的、独立的用户模块，支持多租户的账号、应用、权限、角色管理以及私有化部署场景下的单点登录功能。

    结合了RBAC与ABAC模型，支持灵活地对用户进行权限控制。

    以暴露http和trpc接口的方式，向业务提供登录/注册/用户信息/权限控制等等接口，基于JWT来实现客户身份校验。
- 智能语音电话

    前端基于WebRTC的方式实现在线电话，我们后台经过运营商拿到语音流，实时ASR（Automatic Speech Recognition）转成文字，再结合NLP能力识别其中的手机号、身份证号、人名、地点名，并实时推送到前端，为用户提供即时的文字转录以及核心信息快速提取的功能。
    - 难点
        - 私有化部署情况下，由云函数到自实现ws服务器的迁移问题
        
            项目立项时是以一个SAAS服务的方式部署在腾讯云上，业务业务原本都是采用云函数开发的，后添加了统一的适配层改造成koa服务部署在k8s上；原本采用API网关+触发函数实现的ws服务，需要改用自制的ws服务，在此背景下基于nodejs的websocket包实现了；但是其内部的连接断开事件频繁无法触发（客户端已经断开了，服务端却没有触发destroy逻辑），于是基于redis的set实现了心跳检查机制。
        - 高并发要求下的单点性能瓶颈问题

            疫情突发时，会有大量的流调员同时使用系统拨打电话，最高时达到近千条ws连接，实时转录服务多个节点只能向一个ws节点回写数据，造成很大的性能瓶颈。ws服务CPU和内存占用极高，前端明显感觉到转录推送延时剧增。

            于是对ws服务进行多节点改造，每个pod启动时，会向redis里注册自己的pod_ip, ws的service会把ws连接负载均衡到多个pod，连接建立之后，服务端生成conn_id，客户端则会上报call_id，服务端将二者的映射关系写入redis。
            
            系统所有ws连接的conn_id与连接所在pod的pod_ip存储在redis中，当转录服务收到一则message后则根据call_id查询对应connection信息，并去redis中查询当前pod是否还存活，如果存活则动态调用这个wspod的http接口来回写消息。

            另外基于k8s的Horizontal Pod Autoscaler，监听ws服务的CPU和内存占用，当任意指标超过80%时，则扩容1/2；当某个pod两个指标都小于10%则缩容。缩容之前会触发PreStop的钩子，我们会通过configmap往镜像的目录里注入一个preClose.sh的脚本，内部会执行redis的hdel指令将该pod_ip注册的那个key移除，则后续指向该通电话的转录消息会暂存在内存里一段时间而不会立即推送到前端；pod销毁后，前端发现ws连接断开，则会重新发起连接，并二次上报call_id，至此推送数据通路重新建立，转录服务内存中暂存的消息会有定时任务做重试。

- 数据结构重构

    早期业务逻辑简单但迭代速度极快，后端基于几个核心实体创建了较少的单表，且其中有很多json大字段，难以满足不断新增的数据流转、复杂条件查询、聚合统计等需求，同时随着疫情加重，每日系统新增数据量暴增，急需数据结构的重新设计和代码重构。

    - 难点
        - 业务数据复杂、数据敏感性极高，权限控制粒度极细。
        - 系统每日会录入大量确诊阳性、疑似阳性、密切接触者信息，而基于这些信息又会延伸出14天的轨迹、重点场所、次级密切接触者等众多信息，呈指数级增长。
        - 未来可能需要对接上下游众多疾控系统，数据结构拓展性要求高。
    - 解决
        - 牵头与产品讨论规划未来可能储存在的需求，对当前业务模型进行抽象，基于 病例->日期->事件->重点场所->密切接触者 的实体概念构建E-R图，保障了后期迭代的顺利开展。（重点场所归一、传染溯源分析）
        - 根据时间分库
            
            流调背景下，只关心阳性病人过去14天的行程轨迹，过期的数据业务并不关心（流调任务需要在上报之后尽可能快地部署执行）。于是我们以每个月的1号和16号作为库的划分节点，每到一个节点就创建新库，此后上报的阳性病例以及其衍生数据都写入新库。

            dao层缓存病例创建时间以及数据库之间的映射关系，从而实现不同病例数据的db路由。
        - 根据行政区分表
            
            涉疫相关的任务在各个行政区之间是隔离进行的，各区疾控都希望自己的涉疫数据相对保密。在此背景下，领导提出了区域数据隔离、跨区任务协同的需求。

            原有的实现完全没有考虑行政区的限制，如果要改的话，整个后台逻辑里几百条sql全都要一对一分析、修改，几乎全部的业务接口入参也都要修改。

            于是我们采用了核心业务表的按区水平分表，并在dao层增加统一的路由逻辑，基于查询数据的主键，来拿到其行政区信息，进而对原sql的表名进行替换，以较低的成本完成了业务的改造。

            另一方面对于存量数据，我们基于原有表结构到新表结构的映射关系，编写迁移脚本，在凌晨发版停机阶段进行数据迁移和测试（双写迁移的代码改造成本反而更高）。
- 重点场所合并问题

    流调过程中，需要对阳性病人过去14天的行程以事件为单位进行详细调查，其中会有很多地理位置的录入，我们需要将这些散落在多个事件中的地点进行关联、合并、去重，针对其中的同一个地点进行消杀和采样任务的部署，也要用作重点场所的统计和展示。

    这里就有一个问题，流调员录入的地理位置不一定每次都完全一样，有可能是手工录入「腾讯大厦」，也可能是基于ASR的地理位置提取录入「深南大道10000号腾讯大厦」，此二者本质上是同一个地点，但是录入系统的名称和经纬度都不是完全一样。

    在此背景下，我基于Jaro Winkler算法和redis的geospatial解决了这个问题。

    - Jaro Winkler是一种支持中文字符串比较的相似度计算算法。相较于常用的编辑距离算法、n-gram匹配算法来说，能够更好地表征两个较短中文字符串之间的相似度。
    - 使用redis的geospatial存储14天轨迹中所有地理位置的经纬度信息，通过georadius命令查询每一个位置100米范围内的其他地点，如果这两个地点的名称在经过JW算法计算后，能够得到大于0.9的相似度，那么就由系统自动合并，那些相似度不够的则会加上一个标志位，在业务侧由流调员进行人工判别。

- 流调报告生成器

    流调系统最核心的功能就是输出14天轨迹的流调报告，在最早的实现中，是在业务侧利用officegen调用api来一行一行填充报告内容，如此输出报告的固定文本内容、排版格式、动态字段绑定关系完全硬编码，一旦出现流调报告的内容变更，就需要改写代码并重新发布后台服务；另一方面，各个行政区领导所要求的流调报告格式与填充字段五花八门，业务中生成不同版本报告的代码逻辑一度超过5000行。

    在此背景下，我负责调研并实现了一个基于模板文件的报告生成器。只需要基于写着任意内容的docx文件，在想要替换数据的位置添加批注，并在批注中填入对应的要素id并上传至服务器，业务就可以一行代码生成内容替换之后的报告文件。能够非常简单、快捷地绑定所有业务字段，并保留原模板的几乎所有排版、字体、格式信息。

    当时调研方向大概有三：
    1. 寻找office word相关的SDK，读取模板文件的排版、字体、样式等等信息，套用到新生成的docx文件中。实际测试下来发现排版样式文件纷繁负责，编码难度极高，几乎不可能全部获取并套用。
    2. 寻找相关SDK，读取并替换docx文件中的文本内容。调研下来没有发现这种东西。
    3. 从docx文件的底层数据结构入手，解析元数据并替换。实测下来发现可行。

    word中的文件自Office 2007之后就采用MS-DOC格式进行数据存储，它底层是经zip压缩后的OOXML结构（Office Open XML），可以简单理解为以XML格式存储word中的内容。

    最后通过支持同辈节点顺序解析的一个库实现了OOXML到jsonObject的解析；在解析成jsonObject后，提取其中批注节点内的要素id，并替换成对应的业务字段值，最后再将其还原成OOXML。